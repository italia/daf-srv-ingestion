{
  "name": "ingestion",
  "description": "ingestion workflow",
  "version": 1,
  "tasks": [
    {
      "name": "spark-job-launch",
      "taskReferenceName": "spark-job-launch",
      "inputParameters": {
        "input_spark_task": {
			"code": [
                    "import it.gov.daf.ingestion.hadoop.{CsvChars, SparkOperations}",
                    "val file = \"\"\"${workflow.input.ingestionInput.file}\"\"\"",
                    "val isCsv=${workflow.input.ingestionInput.isCsv}",
                    "val phUri = \"\"\"${workflow.input.ingestionInput.datasetPath}${workflow.input.ingestionInput.datasetName}\"\"\"",
                    "val csvChars = CsvChars( \"\"\"${workflow.input.ingestionInput.csvChars.quote}\"\"\", \"\"\"${workflow.input.ingestionInput.csvChars.delimiter}\"\"\", \"\"\"${workflow.input.ingestionInput.csvChars.escape}\"\"\" )",
                    "SparkOperations.callValidateIngestedFile(None, file, isCsv, Some(csvChars), phUri, spark)"
            ],
            "authHeader": {
                "name":"${workflow.input.ingestionInput.authHeader.name}",
                "authType": "${workflow.input.ingestionInput.authHeader.authType}",
                "token":"${workflow.input.ingestionInput.authHeader.token}"
            }

	    }
      },
      "type": "SIMPLE"
    },
    {
      "name": "call-refresh-table",
      "taskReferenceName": "refresh-table",
      "inputParameters": {
        "http_request": {
          "uri": "${workflow.input.ingestionInput.env.sec-man-url}/impala/refreshTable?schemaName=${workflow.input.ingestionInput.schemaName}&tableName=${workflow.input.ingestionInput.tableName}",
          "method": "PUT",
          "body": {},
          "headers":{
            "Authorization": "${workflow.input.ingestionInput.authHeader.authType} ${workflow.input.ingestionInput.authHeader.token}"
          }
        }
      },
      "type": "HTTP"
    },
    {
      "name": "call-move-uploaded-file",
      "taskReferenceName": "move-uploaded-file",
      "inputParameters": {
        "http_request": {
          "uri": "${workflow.input.ingestionInput.env.sec-man-url}/hdfs/proxy${workflow.input.ingestionInput.file}?op=RENAME&destination=${workflow.input.ingestionInput.archivePath}${workflow.input.ingestionInput.datasetName}-${spark-job-launch.workflowInstanceId}",
          "method": "PUT",
          "headers":{
            "Authorization": "${workflow.input.ingestionInput.authHeader.authType} ${workflow.input.ingestionInput.authHeader.token}"
          }
        }
      },
      "type": "HTTP"
    }
  ],
  "outputParameters": {
    "status": "${spark-job-launch.output.result}"
  },
  "schemaVersion": 2
}